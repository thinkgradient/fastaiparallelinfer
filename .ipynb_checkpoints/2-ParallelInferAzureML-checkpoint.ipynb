{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core import Workspace\n",
    "import os\n",
    "# Load workspace authorization details from config.json\n",
    "ws = Workspace.from_config('./config.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.core.runconfig import CondaDependencies, RunConfiguration\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.core.dataset import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"gpu-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_NC6\")\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_name = \"batchinfer\"\n",
    "datastore_name_input =\"batchinfer_ds\"\n",
    "container_name_input =\"inferimages\"\n",
    "account_key = \"e6bARQzIrh4UJ80rpJXs6fbKm1HsMuvuapn4BammQHLGEAln4r/Oi7Sc8jGZlE/Ze6B238XYetYEs0Z8w6HgRw==\"\n",
    "batchscore_blob = Datastore.register_azure_blob_container(ws, \n",
    "                      datastore_name=datastore_name_input, \n",
    "                      container_name= container_name_input, \n",
    "                      account_name=account_name,\n",
    "                      account_key=account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name_results =\"infer_results\"\n",
    "container_name_results =\"results\"\n",
    "infer_results_data = Datastore.register_azure_blob_container(ws, \n",
    "                      datastore_name=datastore_name_results, \n",
    "                      container_name= container_name_results, \n",
    "                      account_name=account_name,\n",
    "                      account_key=account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python scripts folder\n",
    "scripts_folder = './infercode'\n",
    "script_file = 'score.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferimages = 'inferimages'\n",
    "\n",
    "path_on_datastore = batchscore_blob.path('/')\n",
    "input_ds = Dataset.File.from_files(path=path_on_datastore, validate=False)\n",
    "registered_ds = input_ds.register(ws, inferimages, create_new_version=True)\n",
    "named_ds = registered_ds.as_named_input(inferimages)\n",
    "\n",
    "\n",
    "output_dir = PipelineData(name=\"processed_image\", \n",
    "                          datastore=infer_results_data, \n",
    "                          output_path_on_compute=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_GPU_IMAGE\n",
    "\n",
    "batch_conda_deps = CondaDependencies.create(pip_packages=[\"fastai\",\"torch\",\"torchvision\", \"ipython\", \"scikit-learn\"])\n",
    "\n",
    "batch_env = Environment(name=\"batch_environment\")\n",
    "batch_env.python.conda_dependencies = batch_conda_deps\n",
    "batch_env.docker.enabled = True\n",
    "#batch_env.docker.base_image = DEFAULT_GPU_IMAGE\n",
    "batch_env.docker.base_image = 'mcr.microsoft.com/azureml/base-gpu:openmpi3.1.2-cuda10.0-cudnn7-ubuntu16.04'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.contrib.pipeline.steps import ParallelRunStep, ParallelRunConfig\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=scripts_folder,\n",
    "    entry_script=script_file,\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=compute_target,\n",
    "    node_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model_name = 'model-resnet18.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "# Register the downloaded model \n",
    "model = Model.register(model_path=os.path.join('models', pickled_model_name),\n",
    "                       model_name=\"model-resnet18\",\n",
    "                       tags={'pretrained': \"mnist\"},\n",
    "                       description=\"Resnet trained pytorch model\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.pipeline.steps import ParallelRunStep\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name=\"process-files\",\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[named_ds],  \n",
    "    output=output_dir,\n",
    "    models=[model],\n",
    "    arguments=['--run_invocation_timeout', '1800'],\n",
    "    allow_reuse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "pipeline_run = Experiment(ws, 'image-classification').submit(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
